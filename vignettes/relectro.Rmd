---
title: "relectro"
author: "Kevin Allen"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{relectro}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
This vignette documents the use of the package relectro. relectro is being developped to analyze data from electrophysiological experiments in R. The main aim of this package is to allow users to do common analysis of electrophysiological data within R. The user can them combine the use of relectro with other packages to get the job done quickly. relectro relies on several C functions for computationally intensive segment of the code. This increases the speed of the analysis to a respectable level. 

You can get relectro from the Bitbucket repository of Kevin Allen. If you work with the source code of the package, I would recommand using the `devtools` package to load an build the package. This is especially usefull if you are developping new functions or object for relectro. The package `roxygen2` can be used to add the comments to the code you write.

To install it, you can run R CMD build relectro and R CMD INSTALL relectro.

Below is an introduction to the principal S4 objects within the package and how you can use them. 

More details regarding individual function (e.g. arguments and returned values) can be found within R with the command `?function.name` or by typing `library(help = relectro)`

You can list all the objects (including functions) of relectro with the `ls` function
```{r obj}
#library(relectro)
# or
devtools::load_all("~/repo/relectro/")
ls("package:relectro")
```

The names of the classes start with an upper case letter (e.g. RecSession) whereas the names of functions and methods start a lower case letter (e.g. loadRecSession).

You can also learn more about the internal organisation of an object with the attributes function.
```{r attr}
pt<-new("Positrack")
attributes(pt)
```

## SpikeTrain

This object represent the spike trains of a group of neurons recorded together. The spike trains are usually loaded from files containing the spike times in sample values, the id of the cell firing and the sampling rate. By default, you set the slot `session` within a SpikeTrain object. This is used as main name of the files.  Then call the function `loadSpikeTrain()`. The 3 files loaded have the extension `res`, `clu` and `sampling_rate_dat`. Note that you can also set the data manually with `setSpikeTrain()`. This feature is usefull if you want to work with simulated spike trains. 

Once a SpikeTrain object is set, you can use different functions to do analysis on the spike trains. For example you can calculate spike-train autocorrelations using the function `spikeTimeAutocorrelation()`. You can also calculate the firing rate using `meanFiringRate()`.

Here is an example with simulated spike trains.


```{r simulate_spike_train}
## generate spikes for 3 neurons  
res1<-cumsum(rpois(n=100,lambda=10))
res2<-cumsum(rpois(n=200,lambda=15))
res3<-cumsum(rpois(n=300,lambda=10))
clu<-c(rep(1,100),rep(2,200),rep(3,300))
df<-data.frame(res=c(res1,res2,res3),clu=clu)
df<-df[order(df$res),] # sort according to res values
## create a SpikeTrain object from random spikes ###
st<-new("SpikeTrain")
## set the spike trains in the object
st<-setSpikeTrain(st=st,res=df$res,clu=df$clu,samplingRate=20000)
## get the spike-time autocorrelation
auto<-spikeTimeAutocorrelation(st,binSizeMs=1,windowSizeMs=200)
## plot the autocorrelation
plot(auto$count,type='l',ylab="Spike count", xlab="time (ms)")
## get the mean firing rate
st<-meanFiringRate(st)
st@meanFiringRate
rm(clu,res1,res2,res3,df,auto,st)
```


If you want to calculate a spike-time crosscorrelation between the spikes and some events, you need to set some events within you SpikeTrain object with the function `setEvents()` and then call `spikeTimeCrosscorrelationEvents()`. This could be usefull to see if a cell react to some sort of stimulation or some behavioural events.

Most computations on neuronal activity need to be performed on a limited time period. This is acheived by setting some intervals in the SpikeTime object. You can do this with the function `setIntervals()`. The intervals of the SpikeTrain object are used when analyzing the spatial properties of neurons.

Now here is an example from data files that are provided with the package. This is part of a recording session in which we recorded the activity of the medial entorhinal cortex on a linear track and in a square open-field. In this example, we calculate the spike-time crosscorrelation between the recorded neurons. The first 3 lines of code are to get the session name and path to these files.  

```{r real_spike_trains}
## find the data provided with the package as example
clufile<-unlist(strsplit(x=system.file("extdata", "jp4298-15022016-0106.clu", package = "relectro"), split="/"))
datadir<-paste(clufile[1:length(clufile)-1],sep="/",collapse = "/")
session=strsplit(clufile[length(clufile)],split="\\.")[[1]][1]

st<-new("SpikeTrain",session=session,path=datadir) # create SpikeTrain object
st<-loadSpikeTrain(st) # load res clu and sampling rate
cross<-spikeTimeCrosscorrelation(st,binSizeMs=1,windowSizeMs = 200,probability = T) ## calculate spike-time crosscorrelation
plot(cross$time[which(cross$clu1==2&cross$clu2==5)],cross$prob[which(cross$clu1==2&cross$clu2==5)],ylim=c(0,max(cross$prob[which(cross$clu1==2&cross$clu2==5)])),type='l',ylab="Spike probability",xlab="Time (ms)",main="cc cells 2 and 5") ## plot one crosscorrelation
## set some events, in this case the spikes of clu 2
st<-setEvents(st,events=st@res[which(st@clu==2)])
cc<-spikeTimeCrosscorrelationEvents(st)
plot(cc$time[which(cc$clu==6)],cc$count[which(cc$clu==6)],ylim=c(0,max(cc$count[which(cc$clu==6)])),ylab="Spike count",xlab="Time (ms)",type='l',main="cc spike cells 2 and 6")
rm(cross,cc,clufile)
```

To calculate instantaneous firing rate from the spike trains
```{r ifr}
## calculate instantaneous firing rates
st<-ifr(st)
## plot ifr and spike of a cell
n=400
cell=1
plot(head(st@ifrTime,n),head(st@ifr[cell,],n),type='l',xlab="Time (sec)",ylab="Rate (Hz)")
points(head(st@res[which(st@clu==st@cellList[cell])]/st@samplingRate,n),rep(0,n),col='red')
rm(n,cell)
```

## RecSession

This object read few text files (.par, .desen, .desel, etc) and get the information regarding what was done during the recording session. You can use the RecSession object to get intervals for a given recording environment for example.

```{r recording_session}
rs<-new("RecSession",session=session,path=datadir)
## load configuration data from file
rs<-loadRecSession(rs)
## print session
rs
## get intervals with a given environment
getIntervalsEnvironment(rs,"lt")
```

You can use the intervals provided by the RecSession to limit your analysis of the spike trains to this period. Let say we want to limit an analysis of the spike train to the time the animal was in the environment called sqr70.
```{r recording_session_intervals}
# set the intervals in spike train using output matrix from recSession
stint<-setIntervals(st,s=getIntervalsEnvironment(rs,env="sqr70"))
# print the information of the new spike train
stint
rm(stint)
```
Now the spike train intervals are set to the trial with the sqr70 environment.

## DatFiles

There is a DatFiles class to read the data from one or several .dat files. In this example, we will work with the first .dat file of our recording session. Use a RecSession object to get the information needed to open the file. The .dat file is very short to be able to package it as an example. There is also a function to detect the positive deflection in the voltage (TTL pulses).
```{r DatFiles}
df<-new("DatFiles",fileNames=paste(rs@trialNames[1],"dat",sep="."),path=rs@path,nChannels=rs@nChannels)
data<-datFilesGetOneChannel(df,channelNo=rs@nChannels-1,
                            firstSample=rs@trialStartRes[1],lastSample=rs@samplingRate*10)
plot(data[0:100000],type='l',xlab="sampling",ylab="unscalled values",xlim=c(86000,89000))
ups<-detectUps(as.numeric(data[0:100000]))
downs<-detectDowns(as.numeric(data[0:100000]))
points(ups,rep(0,length(ups)),col="red")
points(downs,rep(0,length(ups)),col="blue")
rm(data,ups,downs)
```


## Positrack
Positrack objects are used to represent the path of the animal during a recording session. The data are loaded from the .whl and .whd files. The example below gives us time intervals for which the animal running speed was between 0 and 3 cm/sec. 

```{r positrack1}
pt<-new("Positrack",session=session,path=datadir)
pt<-loadPositrack(pt)
m<-getIntervalsAtSpeed(pt,0,3)
m[1:10,]
rm(m)
```

One can also use the intervals given by the RecSession object to limit the analysis of the path to these intervals.
```{r positrack2}
pt1<-setInvalidOutsideInterval(pt,s=getIntervalsEnvironment(rs,env="sqr70"))
plot(pt1@x[1:10000],pt1@y[1:10000],col="black", type='l',xlab="x (cm)",ylab="y (cm)")
pt1 # tells you information about valid data.
rm(pt1)
```

You can get the speed of the animal at some define time points
```{r positrack3}
plot(getSpeedAtResValues(pt,res=seq(100000,300000,20)),type='l',xlab="res index",ylab="Running speed (cm/sec)")
```

There is a function to linearize the 2d position data into a 1d representation. This is useful to analyze the data from a linear track. The linear data can be accessed via \code{pt@lin}.
```{r positrack4}
getIntervalsEnvironment(rs,"lt")
pt1<-setInvalidOutsideInterval(pt,s=getIntervalsEnvironment(rs,env="lt"))
pt1<-linearzeLinearTrack(pt1)
n=10000
plot(head(pt1@x[!is.na(pt1@x)],n),
     head(pt1@y[!is.na(pt1@x)],n),
     xlim=c(0,85),ylim=c(0,85))
points(head(pt1@lin[!is.na(pt1@x)],n),
       head(pt1@y[!is.na(pt1@x)],n),
       col="red")
rm(n)
```

You can get intervals of time when the animal was running in a given direction in the linear data as follows.
```{r positrack5}
int<-getIntervalsAtDirection(pt1,direction=1)
## plot an example
s<-140000
e<-s+700
plot(pt1@lin[s:e],ylim=c(0,80))
lines(pt1@dir[s:e]*10,col="red")
points(int[,1]/pt1@resSamplesPerWhlSample-s,
        rep(20,length(int[,1])),col="blue")
points(int[,2]/pt1@resSamplesPerWhlSample-s,
       rep(22,length(int[,1])),col="green")
```



## SpatialProperties2d

Now that you have a recording session, spike trains, and the position data, you can get the spatial properties of the neurons. This is done with the SpatialProperties2d object. Note that the analysis will be limited to the data points that are valid in the Positrack object and within the intervals set in the SpikeTrain object.


```{r spatial_properties1}

sp<-new("SpatialProperties2d",session=session) ## object to get spatial properties
pt<-setInvalidOutsideInterval(pt,s=getIntervalsEnvironment(rs,env="sqr70")) ## select position data for one environment
sp<-firingRateMap2d(sp,st,pt) ## make firing rate maps
sp<-getMapStats(sp,st,pt) ## get info score, sparsity from maps
sp<-mapSpatialAutocorrelation(sp) ## spatial autocorrelation from maps
sp
```

There are not many plotting functions in relectro. I added just enough to be able to see some maps and spatial autocorrelations.
```{r map_plot}
## plot one firing rate map
firingRateMapPlot(m=sp@maps[,,7],name=sp@cellList[7])
firingRateMapAutoPlot(m=sp@autos[,,7],name=sp@cellList[7])
#firingRateMapsPlot(m=sp@maps,names=sp@cellList) ## for a group of maps
#firingRateMapAutosPlot(m=sp@autos,names=sp@cellList) ## for a group of spatial autocorrelations

```

## Loading most objects in a recording session
It is often useful to create and load the spike trains, position data, dat file information, cell infomration when analysing data in a recording session. You can do this by calling `getRecSessionObjects`. This will return a list of loaded objects ready for you to use.
```{r loadObject}
  ## the long way
  st<-new("SpikeTrain",session=rs@session,path=rs@path)
  st<-loadSpikeTrain(st)
  pt<-new("Positrack",session=rs@session,path=rs@path)
  pt<-loadPositrack(pt)
  df<-new("DatFiles",fileNames=paste(rs@trialNames,"dat",sep="."),
          path=rs@path,nChannels=rs@nChannels)
  cg<-new("CellGroup",session=rs@session,path=rs@path,nTetrodes=rs@nElectrodes)
  cg<-loadCellGroup(cg)
  
  ## the short way
  myList<-getRecSessionObjects(rs)
  st<-myList$st
  pt<-myList$pt
  df<-myList$df
  cg<-myList$cg
  rm(myList)
```

## ElectroProject

Projects usually contains several recording sessions from different animals. ElectroProject is a class to represent all your recording session.
Here is an example of a project we have. Normally you would create it with `ep<-new("ElectroProject",directory="/data/projects/vtrack")` and `ep<-setSessionList(ep)` but since you might not have the project on your computer we will load it from the object saved with the package.

```{r electroProject}
  load(paste(datadir,"ep",sep="/"))
  ep
  rss<-getClusteredSessionList(ep)
  oneRs<-rss[[11]] ## get a particular session from the list
  oneRs
```



## Running code on several recording sessions
Now you might want to do some analysis on individual recording session. The trick is to create a function to do the analysis on a single session and then use `lapply` to run the function to individual recording session. 

```{r severalSessions}
myFunction<-function(x){
  return(list(recTime=x@sessionDurationSec,nElectrodes=x@nElectrodes))
  }
## run the function on a single session
myFunction(oneRs)
list.res<-lapply(rss,myFunction) ## returns a list of list
## merge the recTime together
do.call("rbind", sapply(list.res,function(x){x["recTime"]}))

```

You can do all sorts of analysis in your function. I usually return a list of data.frames (e.g. firing rate maps, autocorrelations, etc) and use the  `do.call("rbind")` to merge them together as one data.frame.


##Parallel processing
It is really easy to run code in parallel in R. It is often the case that same analysis is often run on several recording sessions. This is a perfect situation for parallel processing. You can use the `snow` package. You only need to install `snow` and of course `relectro` on all the computers that you want to use for the analysis. Then build a cluster of `workers` that you want to use. Instead of calling `lapply` use `parLapply`. 

If using different computers, you need to load the `relectro` package at the top of the function to make sure they all have access to relectro. You also need to make sure that the other computers have an up-to-date version of relectro.

If your code is almost only reading and writing files, it might be better to run the code sequencially with the lapply function. A good example of this is if you are detecting ttl pulses from the .dat files. Do this sequencially.

Conversely, if your code is processor intensive and has few read/write operations, you can speed up things considerably by increasing the number of threads used.
